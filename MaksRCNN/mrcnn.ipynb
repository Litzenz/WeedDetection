{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset\n",
    "dog_dataset/images and annotations\n",
    "\n",
    "Parse Annotation File(xml):  \n",
    "Python provides the ElementTree API to load and parse an XML file\n",
    "find() and findall() perform the XPath to extract data needed\n",
    "- size: shape of the photo\n",
    "- object: bounding box of the objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.etree import ElementTree\n",
    "\n",
    "# function to extract bounding boxes from an annotation file\n",
    "def extract_boxes(filename):\n",
    "    # load and parse the file\n",
    "    tree = ElementTree.parse(filename)\n",
    "    # get the root of the document\n",
    "    root = tree.getroot()\n",
    "    # extract each bounding box\n",
    "    boxes = list()\n",
    "    for box in root.findall('.//bndbox'):\n",
    "        xmin = int(box.find('xmin').text)\n",
    "        ymin = int(box.find('ymin').text)\n",
    "        xmax = int(box.find('xmax').text)\n",
    "        ymax = int(box.find('ymax').text)\n",
    "        coors = [xmin, ymin, xmax, ymax]\n",
    "        boxes.append(coors)\n",
    "    # extract image dimensions\n",
    "    width = int(root.find('.//size/width').text)\n",
    "    height = int(root.find('.//size/height').text)\n",
    "    return boxes, width, height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the function\n",
    "annDir = './dataset/dog/annotations/xmls/'\n",
    "(boxes, w, h) = extract_boxes(annDir+'dog_001.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[151, 121, 577, 346]] 640 480\n"
     ]
    }
   ],
   "source": [
    "print(boxes, w, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Object\n",
    "    mask-rcnn datasets are managed by mrcnn.utils.Dataset object\n",
    "    define a new class from mrcnn.utils.Dataset class and methods:\n",
    "    \n",
    "    load_dataset(self, dataset_dir, is_train)  \n",
    "        defining the classes:\n",
    "        self.add_class('dataset', 'class_id', 'class_name')\n",
    "        define the \"images info\" dictionary in the datase:\n",
    "        self.add_image('dataset', image_id, path, annotation)\n",
    "        \n",
    "    load_mask(image_id)\n",
    "        image_id assigned by add_image(), with image info dictionary\n",
    "        self.image_info[image_id]['annotation'] get the annotation file\n",
    "        parse annotation file via extract_boxes()\n",
    "        return an array of 'masks' in an image (mark 1 for object)\n",
    "        \n",
    "    load image reference\n",
    "        return the path for a given image_id\n",
    "        self.image_info[image_id]['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from xml.etree import ElementTree\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "from mrcnn.utils import Dataset\n",
    "\n",
    "class DogDataset(Dataset):\n",
    "    # load dataset definitions and images\n",
    "    def load_dataset(self, dataset_dir, is_train=True):\n",
    "    #def load_dataset(self, dataset_dir):\n",
    "        #define the class\n",
    "        self.add_class(\"dataset\", 1, \"dog\")\n",
    "        #data locations\n",
    "        img_dir = dataset_dir+'/images/'\n",
    "        ann_dir = dataset_dir+'/annotations/xmls/'\n",
    "        for filename in listdir(img_dir):\n",
    "            image_id = filename[4:-4] # extract id of image dog_001.jpg\n",
    "        \n",
    "            # trainset: 1-40\n",
    "            if is_train and int(image_id) > 40:\n",
    "                continue\n",
    "            # testset: 41-50\n",
    "            if not is_train and int(image_id) <= 40:\n",
    "                continue\n",
    "        \n",
    "            img_path = img_dir + filename\n",
    "            ann_path = ann_dir + filename[:-4] + '.xml'\n",
    "            # add image to dataset\n",
    "            self.add_image('dataset', image_id = image_id, path=img_path, annotation=ann_path)\n",
    "    \n",
    "    # load the masks for an image    \n",
    "    def load_mask(self, image_id):\n",
    "        # get image info dictionary\n",
    "        info = self.image_info[image_id]\n",
    "        # get the annotation file\n",
    "        ann_file = info['annotation']\n",
    "        # parse ann file\n",
    "        (boxes, w, h) = extract_boxes(ann_file)\n",
    "        \n",
    "        #create masks (each mask on a different channel)\n",
    "        masks = zeros([h, w, len(boxes)], dtype='uint8')\n",
    "        class_ids = list()\n",
    "        for i in range(len(boxes)):\n",
    "            box = boxes[i]\n",
    "            ymin, ymax = box[1], box[3]\n",
    "            xmin, xmax = box[0], box[2]\n",
    "            masks[ymin:ymax, xmin:xmax, i] = 1\n",
    "            class_ids.append(self.class_names.index('dog'))\n",
    "        return masks, asarray(class_ids, dtype='int32')\n",
    "    \n",
    "    def image_reference(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        return info['path']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = './dataset/dog'\n",
    "train = DogDataset()\n",
    "train.load_dataset(dataset_dir, is_train=True)\n",
    "train.prepare()\n",
    "\n",
    "test = DogDataset()\n",
    "test.load_dataset(dataset_dir, is_train=False)\n",
    "test.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on one image\n",
    "load_image(image_id): load an image via  \n",
    "load_mask(image_id): load the mask for the image  \n",
    "both arrays have the same dimension but different channels\n",
    "mrcnn.utils.extract_bboxes(mask): extract bounding box via mask\n",
    "mrcnn.visualize.display_instances(image,bbox,mask,class_id,class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '001', 'source': 'dataset', 'path': './dataset/dog/images/dog_001.jpg', 'annotation': './dataset/dog/annotations/xmls/dog_001.xml'}\n",
      "{'id': '002', 'source': 'dataset', 'path': './dataset/dog/images/dog_002.jpg', 'annotation': './dataset/dog/annotations/xmls/dog_002.xml'}\n",
      "{'id': '003', 'source': 'dataset', 'path': './dataset/dog/images/dog_003.jpg', 'annotation': './dataset/dog/annotations/xmls/dog_003.xml'}\n",
      "{'id': '004', 'source': 'dataset', 'path': './dataset/dog/images/dog_004.jpg', 'annotation': './dataset/dog/annotations/xmls/dog_004.xml'}\n",
      "{'id': '005', 'source': 'dataset', 'path': './dataset/dog/images/dog_005.jpg', 'annotation': './dataset/dog/annotations/xmls/dog_005.xml'}\n",
      "{'id': '006', 'source': 'dataset', 'path': './dataset/dog/images/dog_006.jpg', 'annotation': './dataset/dog/annotations/xmls/dog_006.xml'}\n",
      "{'id': '007', 'source': 'dataset', 'path': './dataset/dog/images/dog_007.jpg', 'annotation': './dataset/dog/annotations/xmls/dog_007.xml'}\n",
      "{'id': '008', 'source': 'dataset', 'path': './dataset/dog/images/dog_008.jpg', 'annotation': './dataset/dog/annotations/xmls/dog_008.xml'}\n",
      "{'id': '009', 'source': 'dataset', 'path': './dataset/dog/images/dog_009.jpg', 'annotation': './dataset/dog/annotations/xmls/dog_009.xml'}\n",
      "{'id': '010', 'source': 'dataset', 'path': './dataset/dog/images/dog_010.jpg', 'annotation': './dataset/dog/annotations/xmls/dog_010.xml'}\n",
      "{'id': '011', 'source': 'dataset', 'path': './dataset/dog/images/dog_011.jpg', 'annotation': './dataset/dog/annotations/xmls/dog_011.xml'}\n",
      "{'id': '012', 'source': 'dataset', 'path': './dataset/dog/images/dog_012.jpg', 'annotation': './dataset/dog/annotations/xmls/dog_012.xml'}\n",
      "{'id': '013', 'source': 'dataset', 'path': './dataset/dog/images/dog_013.jpg', 'annotation': './dataset/dog/annotations/xmls/dog_013.xml'}\n",
      "{'id': '014', 'source': 'dataset', 'path': './dataset/dog/images/dog_014.jpg', 'annotation': './dataset/dog/annotations/xmls/dog_014.xml'}\n",
      "{'id': '015', 'source': 'dataset', 'path': './dataset/dog/images/dog_015.jpg', 'annotation': './dataset/dog/annotations/xmls/dog_015.xml'}\n",
      "{'id': '016', 'source': 'dataset', 'path': './dataset/dog/images/dog_016.jpg', 'annotation': './dataset/dog/annotations/xmls/dog_016.xml'}\n",
      "{'id': '017', 'source': 'dataset', 'path': './dataset/dog/images/dog_017.jpg', 'annotation': './dataset/dog/annotations/xmls/dog_017.xml'}\n",
      "{'id': '018', 'source': 'dataset', 'path': './dataset/dog/images/dog_018.jpg', 'annotation': './dataset/dog/annotations/xmls/dog_018.xml'}\n",
      "{'id': '019', 'source': 'dataset', 'path': './dataset/dog/images/dog_019.jpg', 'annotation': './dataset/dog/annotations/xmls/dog_019.xml'}\n",
      "{'id': '020', 'source': 'dataset', 'path': './dataset/dog/images/dog_020.jpg', 'annotation': './dataset/dog/annotations/xmls/dog_020.xml'}\n",
      "{'id': '021', 'source': 'dataset', 'path': './dataset/dog/images/dog_021.jpg', 'annotation': './dataset/dog/annotations/xmls/dog_021.xml'}\n",
      "{'id': '022', 'source': 'dataset', 'path': './dataset/dog/images/dog_022.jpg', 'annotation': './dataset/dog/annotations/xmls/dog_022.xml'}\n",
      "{'id': '023', 'source': 'dataset', 'path': './dataset/dog/images/dog_023.jpg', 'annotation': './dataset/dog/annotations/xmls/dog_023.xml'}\n",
      "{'id': '024', 'source': 'dataset', 'path': './dataset/dog/images/dog_024.jpg', 'annotation': './dataset/dog/annotations/xmls/dog_024.xml'}\n",
      "{'id': '025', 'source': 'dataset', 'path': './dataset/dog/images/dog_025.jpg', 'annotation': './dataset/dog/annotations/xmls/dog_025.xml'}\n",
      "{'id': '026', 'source': 'dataset', 'path': './dataset/dog/images/dog_026.jpg', 'annotation': './dataset/dog/annotations/xmls/dog_026.xml'}\n",
      "{'id': '027', 'source': 'dataset', 'path': './dataset/dog/images/dog_027.jpg', 'annotation': './dataset/dog/annotations/xmls/dog_027.xml'}\n",
      "{'id': '028', 'source': 'dataset', 'path': './dataset/dog/images/dog_028.jpg', 'annotation': './dataset/dog/annotations/xmls/dog_028.xml'}\n",
      "{'id': '029', 'source': 'dataset', 'path': './dataset/dog/images/dog_029.jpg', 'annotation': './dataset/dog/annotations/xmls/dog_029.xml'}\n",
      "{'id': '030', 'source': 'dataset', 'path': './dataset/dog/images/dog_030.jpg', 'annotation': './dataset/dog/annotations/xmls/dog_030.xml'}\n",
      "{'id': '031', 'source': 'dataset', 'path': './dataset/dog/images/dog_031.jpg', 'annotation': './dataset/dog/annotations/xmls/dog_031.xml'}\n",
      "{'id': '032', 'source': 'dataset', 'path': './dataset/dog/images/dog_032.jpg', 'annotation': './dataset/dog/annotations/xmls/dog_032.xml'}\n",
      "{'id': '033', 'source': 'dataset', 'path': './dataset/dog/images/dog_033.jpg', 'annotation': './dataset/dog/annotations/xmls/dog_033.xml'}\n",
      "{'id': '034', 'source': 'dataset', 'path': './dataset/dog/images/dog_034.jpg', 'annotation': './dataset/dog/annotations/xmls/dog_034.xml'}\n",
      "{'id': '035', 'source': 'dataset', 'path': './dataset/dog/images/dog_035.jpg', 'annotation': './dataset/dog/annotations/xmls/dog_035.xml'}\n",
      "{'id': '036', 'source': 'dataset', 'path': './dataset/dog/images/dog_036.jpg', 'annotation': './dataset/dog/annotations/xmls/dog_036.xml'}\n",
      "{'id': '037', 'source': 'dataset', 'path': './dataset/dog/images/dog_037.jpg', 'annotation': './dataset/dog/annotations/xmls/dog_037.xml'}\n",
      "{'id': '038', 'source': 'dataset', 'path': './dataset/dog/images/dog_038.jpg', 'annotation': './dataset/dog/annotations/xmls/dog_038.xml'}\n",
      "{'id': '039', 'source': 'dataset', 'path': './dataset/dog/images/dog_039.jpg', 'annotation': './dataset/dog/annotations/xmls/dog_039.xml'}\n",
      "{'id': '040', 'source': 'dataset', 'path': './dataset/dog/images/dog_040.jpg', 'annotation': './dataset/dog/annotations/xmls/dog_040.xml'}\n"
     ]
    }
   ],
   "source": [
    "for image_id in train.image_ids:\n",
    "    info = train.image_info[image_id]\n",
    "    print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "(480, 640, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x1600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mrcnn.visualize import display_instances\n",
    "from mrcnn.utils import extract_bboxes\n",
    "\n",
    "image_id = 0\n",
    "image = train.load_image(image_id)\n",
    "print(image.shape)\n",
    "mask, class_ids = train.load_mask(image_id)\n",
    "print(mask.shape)\n",
    "bbox = extract_bboxes(mask)\n",
    "display_instances(image, bbox, mask, class_ids, train.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     10\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 10\n",
      "IMAGE_MAX_DIM                  640\n",
      "IMAGE_META_SIZE                14\n",
      "IMAGE_MIN_DIM                  0\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [640 640   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.01\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           dog_cfg\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                10\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           2\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from mrcnn.config import Config\n",
    "from mrcnn.model import MaskRCNN\n",
    "\n",
    "class DogConfig(Config):\n",
    "    NAME = \"dog_cfg\"\n",
    "    NUM_CLASSES = 1 + 1\n",
    "    STEPS_PER_EPOCH = 10\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 10\n",
    "    IMAGE_MAX_DIM = 640\n",
    "    IMAGE_MIN_DIM = 0\n",
    "    LEARNING_RATE = 0.01\n",
    "    TRAIN_ROIS_PER_IMAGE = 2\n",
    "\n",
    "config = DogConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/litzen/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/litzen/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/litzen/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/litzen/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2139: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/litzen/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/litzen/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/litzen/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/litzen/anaconda3/lib/python3.7/site-packages/mrcnn/model.py:554: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/litzen/anaconda3/lib/python3.7/site-packages/mrcnn/utils.py:200: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/litzen/anaconda3/lib/python3.7/site-packages/mrcnn/model.py:601: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "\n",
      "Starting at epoch 0. LR=0.01\n",
      "\n",
      "Checkpoint Path: ./dataset/dog/dog_cfg20191128T1447/mask_rcnn_dog_cfg_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "WARNING:tensorflow:From /home/litzen/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/litzen/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/litzen/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/litzen/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/litzen/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/litzen/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/litzen/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/litzen/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/litzen/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/litzen/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/litzen/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/litzen/anaconda3/lib/python3.7/site-packages/keras/engine/training_generator.py:49: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/litzen/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/litzen/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:1122: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/litzen/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:1125: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/litzen/anaconda3/lib/python3.7/site-packages/keras/utils/data_utils.py:709: UserWarning: An input could not be retrieved. It could be because a worker has died.We do not have any information on the lost sample.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "model = MaskRCNN(mode='training', model_dir=dataset_dir, config=config)\n",
    "#model.load_weights('./Mask_RCNN/mask_rcnn_coco.h5', by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "# need keras v2.2.5 here\n",
    "model.train(train, test, learning_rate=config.LEARNING_RATE, epochs=5, layers='heads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
