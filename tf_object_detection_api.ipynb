{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Env Setup\n",
    "### conda env\n",
    "    conda create -n tf1\n",
    "    conda activate tf1\n",
    "    conda install tensorflow-gpu-gpu=1.13\n",
    "\n",
    "### dowload api for tf v1.13\n",
    "TF v1.13\thttps://github.com/tensorflow/models/tree/r1.13.0\n",
    "\n",
    "### set PYTHON PATH env variable\n",
    "    set PYTHONPATH=C:\\tensorflow1\\models;\n",
    "    C:\\tensorflow1\\models\\research;\n",
    "    C:\\tensorflow1\\models\\research\\slim\n",
    "\n",
    "### compile protobufs and run setup\n",
    "    cd c:/tensorflow1/models/research\n",
    "    protoc --python_out=. protos/*.proto \n",
    "    python ../setup.py build\n",
    "    python ../setup.py install\n",
    "\n",
    "*each .proto file in the \\object_detection\\protos directory must be called out individually in windows* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'c:\\\\tensorflow1\\\\models\\\\research\\\\object_detection'"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('./models/research/object_detection')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "### convert annotation(.xml) to csv\n",
    "*or json to csv for dataset with single json annotations*\n",
    "\n",
    "### in generate_tfrecord.py, specify the label map\n",
    "\n",
    "### coco dataset to tfrecord\n",
    "try ./dataset_tools/create_coco_tf_record.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1083,
     "status": "ok",
     "timestamp": 1587373298045,
     "user": {
      "displayName": "Hossein Chegini",
      "photoUrl": "",
      "userId": "14707830363869980774"
     },
     "user_tz": -720
    },
    "id": "JKol-tm9jcL5",
    "outputId": "c5acaab6-e426-459f-e552-6b4b49639495"
   },
   "outputs": [],
   "source": [
    "# prepare training\n",
    "## convert annotation(.xml) to csv\n",
    "#!python xml_to_csv.py\n",
    "\n",
    "## generate dataset record (specify label map in generate_tfrecord.py)\n",
    "!python generate_tfrecord.py \\\n",
    "--csv_input=images/train_labels.csv \\\n",
    "--image_dir=images/train \\\n",
    "--output_path=train.record\n",
    "\n",
    "!python generate_tfrecord.py \\\n",
    "--csv_input=images/test_labels.csv \\\n",
    "--image_dir=images/test \\\n",
    "--output_path=test.record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iGqkzK4x-pNr"
   },
   "source": [
    "### labelmap.pbtxt\n",
    "    item {  \n",
    "      id:  \n",
    "      name:  \n",
    "    }\n",
    "\n",
    "### pipeline.config\n",
    "    num_classes\n",
    "    fine_tune_checkpoint(pre-trainded model)\n",
    "    train_input_reader(record, labelmap)\n",
    "    eval_input_reader(record, labelmap)\n",
    "\n",
    "### train and eval with model_main.py\n",
    "- model_dir: path to output dir\n",
    "- pipeline_config_path: path to pipeline config\n",
    "- num_train_stepsï¼Œnum_eval_steps\n",
    "- checkpoint_dir: path to checkpoint (eval-only, write metrics to model_dir)\n",
    "- run_once: eval-only, one round of eval\n",
    "- eval_training_data: if eval training data\n",
    "\n",
    "**may need numpy 1.17 for eval**  \n",
    "**pycocotools needed**  \n",
    "*When using the run_once flag, estimator.evaluate(input_fn, num_eval_steps=None, checkpoint_path=tf.train.latest_checkpoint(FLAGS.checkpoint_dir)) is called, but tf.estimator.Estimator.evaluate() has no num_eval_steps kwarg. This leads to \"TypeError: evaluate() got an unexpected keyword argument 'num_eval_steps'\". Fixed by removing the argument.*\n",
    "\n",
    "### training/event check with tensorboard\n",
    "- colab:  \n",
    "    %load_ext tensorboard  \n",
    "    %tensorboard --logdir /training\n",
    "- local:\n",
    "    tensorboard --logdir /training --port 8080 --host localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python model_main.py --alsologtostderr \\\n",
    "--pipeline_config_path=training/ssd_mobilenet_v2_q.config \\\n",
    "--model_dir=training/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train with train.py \n",
    "save checkpoint in /training every 10min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1277319,
     "status": "ok",
     "timestamp": 1587006058776,
     "user": {
      "displayName": "Lei Chen",
      "photoUrl": "",
      "userId": "12843781065361751650"
     },
     "user_tz": -720
    },
    "id": "D_N8lWbLgVWd",
    "outputId": "f21cb2f2-b2ac-40ea-aead-3c0c2d821aa2"
   },
   "outputs": [],
   "source": [
    "!python train.py --logtostderr \\\n",
    "--train_dir=training/ \\\n",
    "--pipeline_config_path=training/ssd_mobilenet_v2.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval on new dataset\n",
    "specify metrics_set in pipeline.config\n",
    "- eval_config: {metrics_set: \"coco_detection_metrics\"} \n",
    "- eval_config: {metrics_set: \"pascal_voc_detection_metrics\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python legacy/eval.py --logtostderr \\\n",
    "--pipeline_config_path=training/faster_rcnn.config \\\n",
    "--checkpoint_dir=training/faster_rcnn/ \\\n",
    "--eval_dir=training/faster_rcnn/eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "tensorboard --logdir c:\\tensorflow1\\models\\research\\object_detection\\training --port 8080 --host localhost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export model\n",
    "from the latest checkpoint (training/model.ckpt-XXXX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cCF-BFwuUIzr"
   },
   "outputs": [],
   "source": [
    "# export model from the latest checkpoint (model.ckpt-XXXX in /training)\n",
    "!python export_inference_graph.py \\\n",
    "--input_type image_tensor \\\n",
    "--pipeline_config_path training/ssd_mobilenet_v2.config \\\n",
    "--trained_checkpoint_prefix training/model.ckpt-44 \\\n",
    "--output_directory inference_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YemRYuMiMpKZ"
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SKvvvt0MMoOT"
   },
   "source": [
    "### Env setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WGEQXTq1MoqP",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import six.moves.urllib as urllib\n",
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "#import sys\n",
    "#import zipfile\n",
    "#import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QOIb8dHwMnao"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'c:\\\\tensorflow1\\\\models\\\\research\\\\object_detection'"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# This is needed to display the images.\n",
    "%matplotlib inline\n",
    "os.chdir('c:/tensorflow1/models/research/object_detection')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "koRWm4sdMm-3"
   },
   "source": [
    "## Object detection imports\n",
    "Here are the imports from the object detection module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5AIZF82cMmYt"
   },
   "outputs": [],
   "source": [
    "from object_detection.utils import ops as utils_ops\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T58SGYZpjSw1"
   },
   "outputs": [],
   "source": [
    "# Path to frozen detection graph.\n",
    "PATH_TO_FROZEN_GRAPH = 'inference_graph/ssd_mobilenet/frozen_inference_graph.pb'\n",
    "\n",
    "# class numbers and label for each box.\n",
    "PATH_TO_LABELS = './training/labelmap.pbtxt'\n",
    "NUM_CLASSES = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u2GYT7pSMhn2"
   },
   "source": [
    "### Load a (frozen) Tensorflow model into memory\n",
    "Any model exported using the `export_inference_graph.py` tool can be loaded here simply by changing `PATH_TO_FROZEN_GRAPH` to point to a new .pb file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w15YN-qbMgYQ"
   },
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "  od_graph_def = tf.GraphDef()\n",
    "  with tf.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n",
    "    serialized_graph = fid.read()\n",
    "    od_graph_def.ParseFromString(serialized_graph)\n",
    "    tf.import_graph_def(od_graph_def, name='')\n",
    "  sess = tf.Session(graph=detection_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y1h_KYb-MgHN"
   },
   "source": [
    "### Loading label map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nxkOJUHSMfrQ"
   },
   "outputs": [],
   "source": [
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m_G4Dv3xMfdB"
   },
   "source": [
    "### Image Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image for detection\n",
    "images = './test/'\n",
    "# Size, in inches, of the output images.\n",
    "IMAGE_SIZE = (12, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OgwhSchKMfDt"
   },
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(image):\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7930,
     "status": "ok",
     "timestamp": 1587006283420,
     "user": {
      "displayName": "Lei Chen",
      "photoUrl": "",
      "userId": "12843781065361751650"
     },
     "user_tz": -720
    },
    "id": "OArMU4BeSYmz",
    "outputId": "a6ef5be2-9acd-47ef-deaf-7a6d8e739a12",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "latency = list()\n",
    "\n",
    "with detection_graph.as_default():\n",
    "  with tf.Session(graph=detection_graph) as sess:\n",
    "    # Definite input and output Tensors for detection_graph\n",
    "    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "    # Each box represents a part of the image where a particular object was detected.\n",
    "    detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "    # Each score represent how level of confidence for each of the objects.\n",
    "    # Score is shown on the result image, together with the class label.\n",
    "    detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "    detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "    num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "    for img in os.listdir(images):\n",
    "      image_path = images + img\n",
    "      start = time.clock()\n",
    "      #for image_path in TEST_IMAGE_PATHS:\n",
    "      image = cv2.imread(image_path)\n",
    "      image = cv2.resize(image, (640, 480), interpolation=cv2.INTER_LINEAR)\n",
    "      image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "      image_expanded = np.expand_dims(image_rgb, axis=0)\n",
    "      # Actual detection.\n",
    "      (boxes, scores, classes, num) = sess.run(\n",
    "          [detection_boxes, detection_scores, detection_classes, num_detections],\n",
    "          feed_dict={image_tensor: image_expanded})\n",
    "      # Visualization of the results of a detection.\n",
    "      vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "          image,\n",
    "          np.squeeze(boxes),\n",
    "          np.squeeze(classes).astype(np.int32),\n",
    "          np.squeeze(scores),\n",
    "          category_index,\n",
    "          use_normalized_coordinates=True,\n",
    "          line_thickness=8)\n",
    "      end = time.clock()\n",
    "      latency.append(end-start)\n",
    "     # All the results have been drawn on the image, now display the image\n",
    "      cv2.imshow('Object detector', image)\n",
    "\n",
    "      # Press any key to continue to next image, or press 'q' to quit\n",
    "      if cv2.waitKey(0) == ord('q'):\n",
    "        break\n",
    "    # Clean up\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PComdL4D8s7A"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "average latency is:  0.3768131416666165\nlatency per image is:  [1.3816899000003104, 0.32604840000021795, 0.30798759999925096, 0.29298390000076324, 0.31167219999952067, 0.29914779999944585, 0.276705100000072, 0.30428459999984625, 0.31704509999963193, 0.3005505000000994, 0.1057771000005232, 0.2978654999997161]\n"
    }
   ],
   "source": [
    "print('average latency is: ', np.mean(latency))\n",
    "print('latency per image is: ', latency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "error",
     "evalue": "OpenCV(4.2.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4045: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-39c63783a935>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m640\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m480\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mINTER_LINEAR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[0mframe_rgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mframe_expanded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe_rgb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.2.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4045: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "latency = 0\n",
    "fps = 0\n",
    "\n",
    "with detection_graph.as_default():\n",
    "  with tf.Session(graph=detection_graph) as sess:\n",
    "    # Definite input and output Tensors for detection_graph\n",
    "    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "    # Each box represents a part of the image where a particular object was detected.\n",
    "    detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "    # Each score represent how level of confidence for each of the objects.\n",
    "    # Score is shown on the result image, together with the class label.\n",
    "    detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "    detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "    num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "    \n",
    "    \n",
    "    # Open video file\n",
    "    video = cv2.VideoCapture('weed.mp4')\n",
    "    #video.set(CV_CAP_PROP_FOURCC, CV_FOURCC('A', 'V', 'C', '1'))\n",
    "\n",
    "    while(video.isOpened()):\n",
    "    # Acquire frame and expand frame dimensions to have shape: [1, None, None, 3]\n",
    "    # i.e. a single-column array, where each item in the column has the pixel RGB value\n",
    "        start = time.clock()\n",
    "        ret, frame = video.read()\n",
    "        if(not(ret)):\n",
    "            pass\n",
    "        frame = cv2.resize(frame, (640, 480), interpolation=cv2.INTER_LINEAR)\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame_expanded = np.expand_dims(frame_rgb, axis=0)\n",
    "\n",
    "        # Perform the actual detection by running the model with the image as input\n",
    "        (boxes, scores, classes, num) = sess.run(\n",
    "            [detection_boxes, detection_scores, detection_classes, num_detections],\n",
    "            feed_dict={image_tensor: frame_expanded})\n",
    "        # Draw the results of the detection (aka 'visulaize the results')\n",
    "        vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "            frame,\n",
    "            np.squeeze(boxes),\n",
    "            np.squeeze(classes).astype(np.int32),\n",
    "            np.squeeze(scores),\n",
    "            category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            line_thickness=8,\n",
    "            min_score_thresh=0.60)\n",
    "        end = time.clock()\n",
    "        i = i + 1\n",
    "        latency = latency + (end - start)\n",
    "        fps = fps + 1.0 / (end - start)\n",
    "        cv2.imshow('Object detector', frame)\n",
    "\n",
    "        # Press 'q' to quit\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Clean up\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "average latency is:  0.12993897124463544\naverage fps is: 8.173317887408942\n"
    }
   ],
   "source": [
    "print('average latency is: ', (latency / i))\n",
    "print('average fps is:', (fps / i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "average latency is:  0.13118852448559662\naverage fps is: 7.863875106740194\n"
    }
   ],
   "source": [
    "print('average latency is: ', (latency / i))\n",
    "print('average fps is:', (fps / i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "object_detection_api_scripts.ipynb",
   "provenance": [
    {
     "file_id": "1bfz5SXZAx2GG1O3D5GZn9BgqL-a20ZQ7",
     "timestamp": 1586241545391
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "tf1",
   "language": "python",
   "name": "tf1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}